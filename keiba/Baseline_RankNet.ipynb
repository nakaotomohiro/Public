{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline:RankNet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RankNetを用いた競馬着順予測設計\n"
      ],
      "metadata": {
        "id": "xERBOKM9HUfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 概要"
      ],
      "metadata": {
        "id": "T7KclMLkRZmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RankNetを用いて競馬の着順予測を行った。\n",
        "\n",
        "結果、単勝回収率93%-95%の成果を出すことができた(ほぼ同じ条件のlgbmでは70%)。\n",
        "\n",
        "その上で、いくつかの課題を見出すこともできた。\n",
        "- 勝率の計算の仕方の最適解がわからない。\n",
        "- どんな買い方をするのが最適かわからない。\n",
        "- どの程度のデータ量で検証すれば精度算出できるのかわからない。\n",
        "etc..\n"
      ],
      "metadata": {
        "id": "d1xoQoe3RbSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 目的"
      ],
      "metadata": {
        "id": "HzGF8k1wH5B_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "競馬の着順予測のため、RankNetの考え方を転用して深層学習を行う。\n",
        "\n",
        "最終的には以下の2つのうち片方を目標とする。\n",
        "\n",
        "- 単勝回収率100%以上\n",
        "- 複勝回収率100%以上\n",
        "\n",
        "購買は、以下の方法で制御する。\n",
        "\n",
        "- 該当レースにおいて1位予測された馬の単勝を買う。\n",
        "- 該当レースにおいて1, 2, 3位予測された馬の複勝を買う。"
      ],
      "metadata": {
        "id": "P1_CIFjkNBu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 背景"
      ],
      "metadata": {
        "id": "bek_gp4CNEA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランキング学習を選択した背景としては、これまでの学習方法ではレース単位での相対評価が難しかったからである。\n",
        "\n",
        "ランキング学習の手法は多々あるが、今回はその中でRankNetを選択した。理由は後述する。"
      ],
      "metadata": {
        "id": "1exm5O9wJBZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## アルゴリズム"
      ],
      "metadata": {
        "id": "dzSMq_r2Ja0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ランキング学習"
      ],
      "metadata": {
        "id": "EaytdQvMNI0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランキング学習は、その名の通りランキングを予測するための学習方法である。\n",
        "\n",
        "深層学習におけるその損失関数は、以下に大別される。\n",
        "- Pointwise\n",
        "  - 1つのサンプルから損失を定義する。\n",
        "  - 予測結果とgtラベルとの二乗誤差を最小化する。\n",
        "  - 要するにただの回帰による多クラス分類問題である。\n",
        "- Pairwise\n",
        "  - 2つのサンプルから損失を定義する。\n",
        "  - サンプルから2つ選択し、確率の差を取る。真の確率はその差が`>0`, `=0`, `<0` それぞれに`1`, `0`, `1/2`となる。\n",
        "  - 要するに2つのサンプルを比較してどちらが上かを考える。\n",
        "- Listwise\n",
        "  - リスト(今回の場合は1レースに出走する馬のリスト)の全体としていい並び順になっているかどうかを指標とする。\n",
        "\n",
        "Pointwiseでは今回の目的に反し、Listwiseは学習がうまくいかなさそう(競馬は一つのリストが10以上となり、うまくいかなさそう)なので、Pairwiseを選択した。\n"
      ],
      "metadata": {
        "id": "J-wZiLIZNLEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RankNet"
      ],
      "metadata": {
        "id": "JSlgtkMoNMgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RankNetによりPairwiseによるランキング学習を行うことができる。\n",
        "行うことができる、といってもそのようなフレームワークやライブラリがあるわけでもなく、論文の考え方に基づいて普通にコードを書いて実装する。"
      ],
      "metadata": {
        "id": "cg8HedEUNN2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習設計"
      ],
      "metadata": {
        "id": "qRM16lDtNPGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 概要"
      ],
      "metadata": {
        "id": "UC9eHKEENSdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "jrdbからスクレイピングによって取得したデータを加工した上で、\n",
        "Tensorflowを用いてニューラルネットワークを構築する。\n",
        "\n",
        "レース単位での学習を実現するためにジェネレーターを用いる。"
      ],
      "metadata": {
        "id": "FcUhlJ_oNUZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ加工"
      ],
      "metadata": {
        "id": "UBhcytv5NnPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの加工は[別ノート](https://colab.research.google.com/drive/1ejO3POljB5LKak7hLqle3XaKnZ7KtwNe?hl=ja)にて記載。"
      ],
      "metadata": {
        "id": "JiPNRBh3No4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 特徴量"
      ],
      "metadata": {
        "id": "bND3zrLZN2Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEDのデータをベースに特徴量を生成する。\n",
        "- 馬場データ、天候データ、競技場データなどはOne hot Encodingによりダミー変数化を行う。\n",
        "- タイム指標として、各レースのレース時間、前3F, 後3FそれぞれについてTSPを算出する。\n",
        "  - TSPについては、Tomoyuki Takita氏のノートブックを参照。\n",
        "- 前レースの結果を特徴量に入れるため、過去3戦のTSPを当該レースに加える。\n",
        "\n",
        "具体的な特徴量は以下。\n",
        "- 詳細は今度載せます。"
      ],
      "metadata": {
        "id": "b48xo5LUN4dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sed_df = pd.read_csv('/content/drive/MyDrive/競馬/nakao_work/sed_union_nbt_ounull_getdummies.csv')\n",
        "\n",
        "sed_df['レースid'] = (sed_df['競争成績キー_年月日'])*10000 + sed_df['レースキー_場コード_1']*1 + sed_df['レースキー_場コード_2']*2 + sed_df['レースキー_場コード_3']*3 + sed_df[ 'レースキー_場コード_4']*4 + sed_df[ 'レースキー_場コード_5']*5 + sed_df[ 'レースキー_場コード_6']*6 + sed_df['レースキー_場コード_7']*7 + sed_df[ 'レースキー_場コード_8']*8 + sed_df[ 'レースキー_場コード_9']*9 + sed_df[ 'レースキー_場コード_10']*10 + sed_df['レースキー_R']*200\n",
        "\n"
      ],
      "metadata": {
        "id": "AUzyIoBGQbJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = sed_df[\"レースid\"].value_counts(sort=True).where(lambda d:d>=2).dropna()\n",
        "sed_df_not1 = sed_df[sed_df[\"レースid\"].isin(res.index)]"
      ],
      "metadata": {
        "id": "YFltOjaijVeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sed_df_not1['レースid'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l50lWHIToIqh",
        "outputId": "7eee24ca-186e-49dc-d7bd-c4d6bdf17ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202109112206    18\n",
              "202110162404    18\n",
              "202111201609    18\n",
              "201412061207    18\n",
              "202112181407    18\n",
              "                ..\n",
              "201402082410     2\n",
              "201401182207     2\n",
              "201401191806     2\n",
              "201401191408     2\n",
              "201401261007     2\n",
              "Name: レースid, Length: 24093, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_columns = ['馬番',\n",
        "       'レース条件_距離', 'レース場条件_重量',\n",
        "       'レース場条件_頭数', '馬成績_斤量',\n",
        "       '10時単勝オッズ', '10時複勝オッズ',\n",
        "       '馬体重', '馬場係数',\n",
        "       '前走1_nsp', '前走2_nsp', '前走3_nsp', '前走1_nsp_前3f', '前走2_nsp_前3f',\n",
        "       '前走3_nsp_前3f', '前走1_nsp_後3f', '前走2_nsp_後3f', '前走3_nsp_後3f',\n",
        "       'レースキー_場コード_1', 'レースキー_場コード_2', 'レースキー_場コード_3', 'レースキー_場コード_4',\n",
        "       'レースキー_場コード_5', 'レースキー_場コード_6', 'レースキー_場コード_7', 'レースキー_場コード_8',\n",
        "       'レースキー_場コード_9', 'レースキー_場コード_10', 'レース条件_トラック情報_芝ダ障害コード_1',\n",
        "       'レース条件_トラック情報_芝ダ障害コード_2', 'レース場条件_トラック情報_右左_1', 'レース場条件_トラック情報_右左_2',\n",
        "       'レース場条件_トラック情報_右左_3', 'レース場条件_トラック情報_内外_1', 'レース場条件_トラック情報_内外_2',\n",
        "       'レース場条件_トラック情報_内外_9', 'レース場条件_馬場状態_10', 'レース場条件_馬場状態_11',\n",
        "       'レース場条件_馬場状態_12', 'レース場条件_馬場状態_20', 'レース場条件_馬場状態_21', 'レース場条件_馬場状態_22',\n",
        "       'レース場条件_馬場状態_30', 'レース場条件_馬場状態_31', 'レース場条件_馬場状態_32', 'レース場条件_馬場状態_40',\n",
        "       'レース場条件_馬場状態_41', 'レース場条件_馬場状態_42', 'レース場条件_種別_11', 'レース場条件_種別_12',\n",
        "       'レース場条件_種別_13', 'レース場条件_種別_14', 'レース場条件_条件_05', 'レース場条件_条件_10',\n",
        "       'レース場条件_条件_16', 'レース場条件_条件_A3', 'レース場条件_条件_OP',]\n",
        "y_columns = ['馬成績_着順_uma']"
      ],
      "metadata": {
        "id": "uIxv6NzFRDFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE8wzeEAqKXp",
        "outputId": "68cdfc8b-db50-4e78-efa5-f6da447a24c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = sed_df_not1[sed_df_not1['競争成績キー_年月日'] < 20200700]\n",
        "valid = sed_df_not1[(sed_df_not1['競争成績キー_年月日'] < 20210000) & (sed_df_not1['競争成績キー_年月日'] > 20200700)]\n",
        "test = sed_df_not1[sed_df_not1['競争成績キー_年月日'] > 20210000]\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "print(len(train))\n",
        "print(len(valid))\n",
        "print(len(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp6DMKD4q3ZG",
        "outputId": "b1b1a237-d0f5-4236-ad2a-351c10aa7895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268786\n",
            "18895\n",
            "40537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = train.groupby('レースid').groups\n",
        "dd = pd.Series(d)\n",
        "train_index_list =dd.reset_index(drop=True)\n",
        "\n",
        "d = valid.groupby('レースid').groups\n",
        "dd = pd.Series(d)\n",
        "valid_index_list =dd.reset_index(drop=True)\n",
        "\n",
        "d = test.groupby('レースid').groups\n",
        "dd = pd.Series(d)\n",
        "test_index_list =dd.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5g4RfqkzVIJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train[X_columns]\n",
        "train_y = train[y_columns]\n",
        "\n",
        "valid_X = valid[X_columns]\n",
        "valid_y = valid[y_columns]\n",
        "\n",
        "test_X = test[X_columns]\n",
        "test_y = test[y_columns]"
      ],
      "metadata": {
        "id": "13XK069MsU7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ジェネレータ"
      ],
      "metadata": {
        "id": "dr1ycykjO0wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "同一レースから2データをサンプリングするためにジェネレータクラスを定義した。"
      ],
      "metadata": {
        "id": "13zw4iOiO5Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RankNetGenerator(object):\n",
        "\n",
        "    def __init__(self, X, y, race_index_list, X_scaler=None, batch_size=32):\n",
        "        self._X = X\n",
        "\n",
        "        self._y = y\n",
        "        # 同一レースのindexを保持するpandas.Seriesのリスト\n",
        "        self._race_index_list = race_index_list\n",
        "\n",
        "        # 説明変数に適用する標準化スケーラ\n",
        "        self._X_scaler = X_scaler \n",
        "\n",
        "        # バッチサイズ\n",
        "        self._batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "    def __next__(self):\n",
        "\n",
        "        # レースをサンプリング\n",
        "        race_indexes = np.random.randint(0, len(self._race_index_list), self._batch_size)\n",
        "        race_indexes = [self._race_index_list[race_index].values for race_index in race_indexes]\n",
        "\n",
        "        # 出走馬をサンプリング\n",
        "        uma_indexes = [race_index[np.random.choice(race_index.shape[0], 2, replace=False)] for race_index in race_indexes]\n",
        "        # タプルの先頭要素がランクが高くなるようにする。ここについては要検討。yを1にする必要はないかも。\n",
        "        uma_indexes = [(idx_1, idx_2) if self._y.loc[idx_1].values < self._y.loc[idx_2].values else (idx_2, idx_1) for idx_1, idx_2 in uma_indexes]\n",
        "\n",
        "        # 説明変数の設定\n",
        "        X = np.array([(self._X.loc[uma_index[0]], self._X.loc[uma_index[1]]) for uma_index in uma_indexes])\n",
        "        X = [self._X_scaler.transform(X[:, 0, :]), self._X_scaler.transform(X[:, 1, :])]\n",
        "\n",
        "        # サンプルした2データの先頭が必ずランクが大きくなるため、全て１.\n",
        "        y = np.ones(self._batch_size)\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "asUSkddCM85G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "class RankNetTestGeneratorForRace(object):\n",
        "\n",
        "    def __init__(self, X, X_scaler=None):\n",
        "\n",
        "        # 説明変数\n",
        "        self._X = X\n",
        "\n",
        "        # 説明変数に適用する標準化スケーラ\n",
        "        self._X_scaler = X_scaler \n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "    def __next__(self):\n",
        "\n",
        "        run_n = len(self._X)\n",
        "        umas = []\n",
        "        for b in range(run_n):\n",
        "          umas.append(b)\n",
        "        uma_indexes = list(itertools.permutations(umas, 2))\n",
        "        batch_size = len(uma_indexes)\n",
        "        \n",
        "\n",
        "        # 説明変数の設定\n",
        "        X = np.array([(self._X.loc[uma_index[0]], self._X.loc[uma_index[1]]) for uma_index in uma_indexes])\n",
        "        X = [self._X_scaler.transform(X[:, 0, :]), self._X_scaler.transform(X[:, 1, :])]\n",
        "\n",
        "        # 真の分布\\bar{p_{ij}}の設定\n",
        "        # サンプルした2データの先頭が必ずランクが大きくなるため、全て１.\n",
        "        y = np.ones(batch_size)\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "BpizhyRTPsXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデル"
      ],
      "metadata": {
        "id": "dQxEXVIDPazm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルはTensorflowによって作った。2つの入力を受け、モデルの出力差分、および活性化関数としてsigmoidを返す。"
      ],
      "metadata": {
        "id": "-YoOspBePcgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StMC0RuRGgeF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def build_nn(input_dim, hidden_dim, output_dim, layer_num, activation, dropout_rate):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "\n",
        "    x = tf.keras.layers.Dense(hidden_dim, activation=activation)(inputs)\n",
        "    for i in range(layer_num):\n",
        "        x = tf.keras.layers.Dense(hidden_dim, activation=activation)(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(output_dim)(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "def build_ranknet(input_dim, hidden_dim, output_dim, layer_num, activation, dropout_rate):\n",
        "    inputs_1 = tf.keras.Input(shape=(input_dim,))\n",
        "    inputs_2 = tf.keras.Input(shape=(input_dim,))\n",
        "\n",
        "    nn = build_nn(input_dim=input_dim, \n",
        "                  hidden_dim=hidden_dim,\n",
        "                  output_dim=output_dim, \n",
        "                  layer_num=layer_num,\n",
        "                  activation=activation,\n",
        "                  dropout_rate=dropout_rate, \n",
        "    )\n",
        "\n",
        "    x1 = nn(inputs_1)\n",
        "    x2 = nn(inputs_2)\n",
        "\n",
        "    subtract = tf.keras.layers.Subtract()([x1, x2])\n",
        "    outputs = tf.keras.layers.Activation('sigmoid')(subtract)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs_1, inputs_2], outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習"
      ],
      "metadata": {
        "id": "yJ3HYoTzQUY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early Stoppingは、validationスコアが5spoch連続で進まなかった場合に行う。"
      ],
      "metadata": {
        "id": "mQyIzUGiRWOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ハイパーパラメータ\n",
        "input_dim = 57                 # モデルの入力(説明変数)の次元数\n",
        "output_dim = 1                  # モデルの出力次元数\n",
        "hidden_dim = 30                # 隠れ層の次元数\n",
        "layer_num = 3                   # 隠れ層数\n",
        "activation = tf.nn.relu         # 活性化関数\n",
        "dropout_rate = 0.1              # ドロップアウト率\n",
        "epoch = 100                     # エポック数\n",
        "train_steps = 1000              # 学習データでの１エポック当たりのステップ数\n",
        "valid_steps = 100               # 開発データでの１エポック当たりのステップ数\n",
        "loss = \"binary_crossentropy\"    # 損失関数\n",
        "optimizer = \"adam\"              # オプティマイザ\n",
        "\n",
        "# 標準化\n",
        "X_scaler = StandardScaler()\n",
        "_ = X_scaler.fit_transform(train_X.values)\n",
        "\n",
        "# ジェネレータ\n",
        "train_generator = RankNetGenerator(train_X, train_y, train_index_list, X_scaler=X_scaler, batch_size=32)\n",
        "valid_generator = RankNetGenerator(valid_X, valid_y, valid_index_list, X_scaler=X_scaler, batch_size=32)\n",
        "\n",
        "# モデル\n",
        "ranknet = build_ranknet(input_dim, hidden_dim, output_dim, layer_num, activation, dropout_rate)\n",
        "\n",
        "# オプティマイザーと損失関数を設定\n",
        "ranknet.compile(optimizer=optimizer,\n",
        "                loss=loss)\n",
        "\n",
        "# Early Stopping\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
        "\n",
        "# 学習\n",
        "model_ranknet = ranknet.fit(train_generator, \n",
        "                            validation_data=valid_generator, \n",
        "                            epochs=epoch,\n",
        "                            batch_size=32,\n",
        "                            callbacks=callbacks, \n",
        "                            steps_per_epoch=train_steps,\n",
        "                            validation_steps=valid_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0dd995a-8ddc-4027-aa35-1722b862b190",
        "id": "SF2LhWJGomEz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 32s 30ms/step - loss: 0.6198 - val_loss: 0.5920\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5795 - val_loss: 0.5858\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5742 - val_loss: 0.5840\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.5730 - val_loss: 0.5940\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5667 - val_loss: 0.5731\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5706 - val_loss: 0.5739\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5632 - val_loss: 0.5904\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5653 - val_loss: 0.5867\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.5718 - val_loss: 0.5838\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5724 - val_loss: 0.5860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XYK9BM6BRgUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 予測"
      ],
      "metadata": {
        "id": "wUCvKnfZRn52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "予測は以下のフローで行う。\n",
        "\n",
        "- 馬Aが馬Bに勝利し、馬Bが馬Cに勝利した場合、馬Aは馬Cに勝利していることを期待し、3すくみの結果になることがない場合\n",
        "1. 各レースに出走する全ての馬での総当たり戦を行う。すなわち、n頭出走する場合はnC2回モデルがpredictionを行う。\n",
        "2. 総当たり戦結果を用い、なんか頑張って1列に順位通り並べる。\n",
        "\n",
        "- そうはならない場合(多分こっち)\n",
        "1. 各馬に対し、他の馬との対戦の勝率を合計する。\n",
        "2. それが勝率。"
      ],
      "metadata": {
        "id": "mh5jkqNBRqWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_x, X_scaler):\n",
        "  # ジェネレータ呼び出し\n",
        "  generator = RankNetTestGeneratorForRace(test_x, X_scaler=X_scaler)\n",
        "  # 予測\n",
        "  ans = model.predict(generator, steps=1)\n",
        "  \"\"\"以下、ランキング付けを行う。現在は勝率の単純累計\"\"\"\n",
        "  uma_n = len(test_x)\n",
        "  syouritu = [0] * uma_n\n",
        "  for index, n in enumerate(ans):\n",
        "    uma_index =  (index // (uma_n -1 ))\n",
        "    syouritu[uma_index] += n\n",
        "  df = pd.DataFrame(syouritu, columns = ['syouritu'])\n",
        "  df['pred_rank'] = df['syouritu'].rank(ascending=False)\n",
        "  return df"
      ],
      "metadata": {
        "id": "AhBhCOM6Ro8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank1_score = 0\n",
        "ranksum_score = 0\n",
        "count = 0\n",
        "money_tansyo = 0\n",
        "fukusyo_count = 0\n",
        "money_fukusyo = 0\n",
        "\n",
        "honki12_tansyo = 0\n",
        "honki12_count = 0\n",
        "honki12_count_hit = 0\n",
        "\n",
        "honki11_tansyo = 0\n",
        "honki11_count = 0\n",
        "honki11_count_hit = 0\n",
        "\n",
        "\n",
        "for index, idx in enumerate(test_index):\n",
        "  if index%100==0:\n",
        "    print(index)\n",
        "  test2 = test[test['レースid']==int(idx)]\n",
        "  test2 = test2.reset_index(drop=True)\n",
        "  test2_X = test2[X_columns]\n",
        "  test2_y = test2[y_columns]\n",
        "  itii = 20\n",
        "  ni = 20\n",
        "  if len(test2) > 0:\n",
        "    count += 1\n",
        "    X_scaler = StandardScaler()\n",
        "    _ = X_scaler.fit_transform(test2_X.values)\n",
        "    # 予測\n",
        "    pred = predict(ranknet, test2_X, X_scaler)\n",
        "    for n in range(len(test2_X)):\n",
        "      if int(pred['pred_rank'][n]) == 1:\n",
        "        itii = n\n",
        "      if int(pred['pred_rank'][n]) == 2:\n",
        "        ni = n\n",
        "      if (int(test2_y['馬成績_着順_uma'][n]) == 1) and (int(test2_y['馬成績_着順_uma'][n]) == int(pred['pred_rank'][n])):\n",
        "        rank1_score += 1\n",
        "        money_tansyo += test2_X['10時単勝オッズ'][n]\n",
        "      if (int(test2_y['馬成績_着順_uma'][n]) < 4) and (int(pred['pred_rank'][n]) < 4):\n",
        "        money_fukusyo += test2_X['10時複勝オッズ'][n]\n",
        "      if (int(pred['pred_rank'][n]) < 4):\n",
        "        fukusyo_count += 1\n",
        "      ranksum_score += (int(test2_y['馬成績_着順_uma'][n]) - int(pred['pred_rank'][n]))**2\n",
        "\n",
        "    if (itii < 20) and (ni < 20) and (pred['syouritu'][itii] > (pred['syouritu'][ni] * 1.2)):\n",
        "      honki12_count += 1\n",
        "      if int(test2_y['馬成績_着順_uma'][itii]) == 1:\n",
        "        honki12_count_hit += 1\n",
        "        honki12_tansyo += test2_X['10時単勝オッズ'][itii]\n",
        "\n",
        "    if (itii < 20) and (ni < 20) and (pred['syouritu'][itii] > (pred['syouritu'][ni] * 1.1)):\n",
        "      honki11_count += 1\n",
        "      if int(test2_y['馬成績_着順_uma'][itii]) == 1:\n",
        "        honki11_count_hit += 1\n",
        "        honki11_tansyo += test2_X['10時単勝オッズ'][itii]\n",
        "        \n",
        "    \n",
        "print(count)\n",
        "print(rank1_score)\n",
        "print(ranksum_score)\n",
        "print(money_tansyo)\n",
        "print(fukusyo_count)\n",
        "print(money_fukusyo)"
      ],
      "metadata": {
        "id": "9g9sJ4zkPywR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('サンプルレース数：{}件'.format(count))\n",
        "print('単勝的中率：{}%'.format(100 * rank1_score/count))\n",
        "print('全着順MSE：{}'.format(ranksum_score/len(test)))\n",
        "print('単勝回収率：{}%'.format(100 * money_tansyo/count))\n",
        "print('複勝回収率：{}%'.format(100 * money_fukusyo/fukusyo_count))\n",
        "\n",
        "print('確率1.2倍時単勝購入回数：{}回'.format(honki12_count))\n",
        "print('確率1.2倍時単勝的中回数：{}回'.format(honki12_count_hit))\n",
        "print('確率1.2倍時単勝回収率：{}%'.format(100 * honki12_tansyo/honki12_count))\n",
        "\n",
        "print('確率1.1倍時単勝購入回数：{}回'.format(honki11_count))\n",
        "print('確率1.1倍時単勝的中回数：{}回'.format(honki11_count_hit))\n",
        "print('確率1.1倍時単勝回収率：{}%'.format(100 * honki11_tansyo/honki11_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkZIxMX-GvFj",
        "outputId": "db9b2a33-13e2-4ea9-f9d7-4cf32c2d1961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "サンプルレース数：3031件\n",
            "単勝的中率：30.419003629165292%\n",
            "全着順MSE：16.754791918494217\n",
            "単勝回収率：93.68195315077536%\n",
            "複勝回収率：83.11888265698951%\n",
            "確率1.2倍時単勝購入回数：97回\n",
            "確率1.2倍時単勝的中回数：38回\n",
            "確率1.2倍時単勝回収率：84.74226804123711%\n",
            "確率1.1倍時単勝購入回数：580回\n",
            "確率1.1倍時単勝的中回数：235回\n",
            "確率1.1倍時単勝回収率：98.62068965517244%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ちなみに、全く同じことをもう一度した場合の成果は下のような感じ。"
      ],
      "metadata": {
        "id": "hsOY1ymFUZgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('サンプルレース数：{}件'.format(count))\n",
        "print('単勝的中率：{}%'.format(100 * rank1_score/count))\n",
        "print('全着順MSE：{}'.format(ranksum_score/len(test)))\n",
        "print('単勝回収率：{}%'.format(100 * money_tansyo/count))\n",
        "print('複勝回収率：{}%'.format(100 * money_fukusyo/fukusyo_count))\n",
        "\n",
        "print('確率1.2倍時単勝購入回数：{}回'.format(honki12_count))\n",
        "print('確率1.2倍時単勝的中回数：{}回'.format(honki12_count_hit))\n",
        "print('確率1.2倍時単勝回収率：{}%'.format(100 * honki12_tansyo/honki12_count))\n",
        "\n",
        "print('確率1.1倍時単勝購入回数：{}回'.format(honki11_count))\n",
        "print('確率1.1倍時単勝的中回数：{}回'.format(honki11_count_hit))\n",
        "print('確率1.1倍時単勝回収率：{}%'.format(100 * honki11_tansyo/honki11_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2c8740-c038-41d3-b2f6-fea6b470cb1d",
        "id": "OzuxHOEzUk2q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "サンプルレース数：3031件\n",
            "単勝的中率：31.111844275816562%\n",
            "全着順MSE：16.76525149863088\n",
            "単勝回収率：95.20950181458265%\n",
            "複勝回収率：83.33553282745034%\n",
            "確率1.2倍時単勝購入回数：90回\n",
            "確率1.2倍時単勝的中回数：34回\n",
            "確率1.2倍時単勝回収率：79.66666666666667%\n",
            "確率1.1倍時単勝購入回数：549回\n",
            "確率1.1倍時単勝的中回数：204回\n",
            "確率1.1倍時単勝回収率：90.78324225865212%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQvI2-aTUk2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結論"
      ],
      "metadata": {
        "id": "NpNmJAodQs3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 前走データ、馬場状態データのみから回収率約94%を達成"
      ],
      "metadata": {
        "id": "Hb4QwuBTQyKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 考察"
      ],
      "metadata": {
        "id": "LD2kvNprViD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 以前、lgbmの2値分類を用いて同じ特徴量で学習を行い、全てのレースで馬券を購入した際、回収率は70%であった。今回は回収率が94%であったため、目覚ましい成果。\n",
        "- 今回勝率を計算する際、めちゃくちゃ単純な計算を行った。改善の余地がありそう。\n",
        "- 何度か全く同じ学習を行った際、単勝回収率は92-95%くらいのブレがあった。\n",
        "- 使用している特徴量がまだまだ全然足りない。増やしたらどの程度精度が変わるだろうか。"
      ],
      "metadata": {
        "id": "GHknNn07Vkv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 議論"
      ],
      "metadata": {
        "id": "H3JlvO41RKav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 特徴量に関して\n",
        "- 騎手データや調教データを入れたい。騎手データはどんな形にすればいいだろうか。\n",
        "  - 勝率、連対率、3着内率から1位、2位、3位の確率を算出して使う\n",
        "\n",
        "### 学習に関して\n",
        "- 今回は学習が進んだが、データ量を半年ほど増やすと損失関数が発散してしまった(`loss:nan`になった)。対処方法がいまいちよくわからない。\n",
        "  - 別のcsvからデータを統合した際の型のエラーだった。解決済み。\n",
        "\n",
        "### 予測に関して\n",
        "- 勝率の計算方法が分からない。1vs1の成績データがいっぱいあるのだから、絶対もっといいやり方があるはず。\n",
        "- ものの数回の学習でも3%程度の精度にずれが出た。また、確率を絞った買い方をした際に(サンプルが少ないこともあって)「より絞った買い方をした方が精度が下がる」なんてこともあった。具体的にどの程度のサンプル数を持てば十分な精度検証ができるのだろうか？\n",
        "  - 5000件での精度を正解とする\n",
        "- 馬券の買い方について。勝率を出せたら単勝は十分な買い方になりうるが、馬単や三連単の方が適してるかも？"
      ],
      "metadata": {
        "id": "1zJ_LB4oRN41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "- 当たっているデータ、当たっていないデータの具体例をピックアップする\n",
        "- 人間のベンチマーク\n",
        "  - 一番人気だけを買い続ける、的な\n",
        "  "
      ],
      "metadata": {
        "id": "MpVTQ91ogHv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z2U9D_NTL9vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}